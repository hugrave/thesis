{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import utils\n",
    "\n",
    "from model import Generator, Discriminator\n",
    "\n",
    "\n",
    "def convert_modconv(vars, source_name, target_name, flip=False):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    mod_weight = vars[source_name + '/mod_weight'].value().eval()\n",
    "    mod_bias = vars[source_name + '/mod_bias'].value().eval()\n",
    "    noise = vars[source_name + '/noise_strength'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {\n",
    "        'conv.weight': np.expand_dims(weight.transpose((3, 2, 0, 1)), 0),\n",
    "        'conv.modulation.weight': mod_weight.transpose((1, 0)),\n",
    "        'conv.modulation.bias': mod_bias + 1,\n",
    "        'noise.weight': np.array([noise]),\n",
    "        'activate.bias': bias,\n",
    "    }\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    if flip:\n",
    "        dic_torch[target_name + '.conv.weight'] = torch.flip(\n",
    "            dic_torch[target_name + '.conv.weight'], [3, 4]\n",
    "        )\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_conv(vars, source_name, target_name, bias=True, start=0):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "\n",
    "    dic = {'weight': weight.transpose((3, 2, 0, 1))}\n",
    "\n",
    "    if bias:\n",
    "        dic['bias'] = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    dic_torch[target_name + f'.{start}.weight'] = torch.from_numpy(dic['weight'])\n",
    "\n",
    "    if bias:\n",
    "        dic_torch[target_name + f'.{start + 1}.bias'] = torch.from_numpy(dic['bias'])\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_torgb(vars, source_name, target_name):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    mod_weight = vars[source_name + '/mod_weight'].value().eval()\n",
    "    mod_bias = vars[source_name + '/mod_bias'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {\n",
    "        'conv.weight': np.expand_dims(weight.transpose((3, 2, 0, 1)), 0),\n",
    "        'conv.modulation.weight': mod_weight.transpose((1, 0)),\n",
    "        'conv.modulation.bias': mod_bias + 1,\n",
    "        'bias': bias.reshape((1, 3, 1, 1)),\n",
    "    }\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def convert_dense(vars, source_name, target_name):\n",
    "    weight = vars[source_name + '/weight'].value().eval()\n",
    "    bias = vars[source_name + '/bias'].value().eval()\n",
    "\n",
    "    dic = {'weight': weight.transpose((1, 0)), 'bias': bias}\n",
    "\n",
    "    dic_torch = {}\n",
    "\n",
    "    for k, v in dic.items():\n",
    "        dic_torch[target_name + '.' + k] = torch.from_numpy(v)\n",
    "\n",
    "    return dic_torch\n",
    "\n",
    "\n",
    "def update(state_dict, new):\n",
    "    for k, v in new.items():\n",
    "        if k not in state_dict:\n",
    "            raise KeyError(k + ' is not found')\n",
    "\n",
    "        if v.shape != state_dict[k].shape:\n",
    "            raise ValueError(f'Shape mismatch: {v.shape} vs {state_dict[k].shape}')\n",
    "\n",
    "        state_dict[k] = v\n",
    "\n",
    "\n",
    "def discriminator_fill_statedict(statedict, vars, size):\n",
    "    log_size = int(math.log(size, 2))\n",
    "\n",
    "    update(statedict, convert_conv(vars, f'{size}x{size}/FromRGB', 'convs.0'))\n",
    "\n",
    "    conv_i = 1\n",
    "\n",
    "    for i in range(log_size - 2, 0, -1):\n",
    "        reso = 4 * 2 ** i\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(vars, f'{reso}x{reso}/Conv0', f'convs.{conv_i}.conv1'),\n",
    "        )\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(\n",
    "                vars, f'{reso}x{reso}/Conv1_down', f'convs.{conv_i}.conv2', start=1\n",
    "            ),\n",
    "        )\n",
    "        update(\n",
    "            statedict,\n",
    "            convert_conv(\n",
    "                vars, f'{reso}x{reso}/Skip', f'convs.{conv_i}.skip', start=1, bias=False\n",
    "            ),\n",
    "        )\n",
    "        conv_i += 1\n",
    "\n",
    "    update(statedict, convert_conv(vars, f'4x4/Conv', 'final_conv'))\n",
    "    update(statedict, convert_dense(vars, f'4x4/Dense0', 'final_linear.0'))\n",
    "    update(statedict, convert_dense(vars, f'Output', 'final_linear.1'))\n",
    "\n",
    "    return statedict\n",
    "\n",
    "\n",
    "def fill_statedict(state_dict, vars, size):\n",
    "    log_size = int(math.log(size, 2))\n",
    "\n",
    "    for i in range(8):\n",
    "        update(state_dict, convert_dense(vars, f'G_mapping/Dense{i}', f'style.{i + 1}'))\n",
    "\n",
    "    update(\n",
    "        state_dict,\n",
    "        {\n",
    "            'input.input': torch.from_numpy(\n",
    "                vars['G_synthesis/4x4/Const/const'].value().eval()\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "\n",
    "    update(state_dict, convert_torgb(vars, 'G_synthesis/4x4/ToRGB', 'to_rgb1'))\n",
    "\n",
    "    for i in range(log_size - 2):\n",
    "        reso = 4 * 2 ** (i + 1)\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_torgb(vars, f'G_synthesis/{reso}x{reso}/ToRGB', f'to_rgbs.{i}'),\n",
    "        )\n",
    "\n",
    "    update(state_dict, convert_modconv(vars, 'G_synthesis/4x4/Conv', 'conv1'))\n",
    "\n",
    "    conv_i = 0\n",
    "\n",
    "    for i in range(log_size - 2):\n",
    "        reso = 4 * 2 ** (i + 1)\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_modconv(\n",
    "                vars,\n",
    "                f'G_synthesis/{reso}x{reso}/Conv0_up',\n",
    "                f'convs.{conv_i}',\n",
    "                flip=True,\n",
    "            ),\n",
    "        )\n",
    "        update(\n",
    "            state_dict,\n",
    "            convert_modconv(\n",
    "                vars, f'G_synthesis/{reso}x{reso}/Conv1', f'convs.{conv_i + 1}'\n",
    "            ),\n",
    "        )\n",
    "        conv_i += 2\n",
    "\n",
    "    for i in range(0, (log_size - 2) * 2 + 1):\n",
    "        update(\n",
    "            state_dict,\n",
    "            {\n",
    "                f'noises.noise_{i}': torch.from_numpy(\n",
    "                    vars[f'G_synthesis/noise{i}'].value().eval()\n",
    "                )\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return state_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = 'cuda'\n",
    "\n",
    "args = {\n",
    "    \"repo\": \"../stylegan2\",\n",
    "    \"path\": \"stylegan2-ffhq-config-f.pkl\"\n",
    "}\n",
    "\n",
    "sys.path.append(args[\"repo\"])\n",
    "\n",
    "import dnnlib\n",
    "from dnnlib import tflib\n",
    "\n",
    "tflib.init_tf()\n",
    "\n",
    "#with open(args[\"path\"], 'rb') as f:\n",
    "#    generator, discriminator, g_ema = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = g_ema.output_shape[2]\n",
    "\n",
    "g = Generator(size, 512, 8, channel_multiplier=args.channel_multiplier)\n",
    "state_dict = g.state_dict()\n",
    "state_dict = fill_statedict(state_dict, g_ema.vars, size)\n",
    "\n",
    "g.load_state_dict(state_dict)\n",
    "\n",
    "latent_avg = torch.from_numpy(g_ema.vars['dlatent_avg'].value().eval())\n",
    "\n",
    "ckpt = {'g_ema': state_dict, 'latent_avg': latent_avg}\n",
    "\n",
    "if args.gen:\n",
    "    g_train = Generator(size, 512, 8, channel_multiplier=args.channel_multiplier)\n",
    "    g_train_state = g_train.state_dict()\n",
    "    g_train_state = fill_statedict(g_train_state, generator.vars, size)\n",
    "    ckpt['g'] = g_train_state\n",
    "\n",
    "if args.disc:\n",
    "    disc = Discriminator(size, channel_multiplier=args.channel_multiplier)\n",
    "    d_state = disc.state_dict()\n",
    "    d_state = discriminator_fill_statedict(d_state, discriminator.vars, size)\n",
    "    ckpt['d'] = d_state\n",
    "\n",
    "name = os.path.splitext(os.path.basename(args.path))[0]\n",
    "torch.save(ckpt, name + '.pt')\n",
    "\n",
    "batch_size = {256: 16, 512: 9, 1024: 4}\n",
    "n_sample = batch_size.get(size, 25)\n",
    "\n",
    "g = g.to(device)\n",
    "\n",
    "z = np.random.RandomState(0).randn(n_sample, 512).astype('float32')\n",
    "\n",
    "with torch.no_grad():\n",
    "    img_pt, _ = g(\n",
    "        [torch.from_numpy(z).to(device)],\n",
    "        truncation=0.5,\n",
    "        truncation_latent=latent_avg.to(device),\n",
    "    )\n",
    "\n",
    "Gs_kwargs = dnnlib.EasyDict()\n",
    "Gs_kwargs.randomize_noise = False\n",
    "img_tf = g_ema.run(z, None, **Gs_kwargs)\n",
    "img_tf = torch.from_numpy(img_tf).to(device)\n",
    "\n",
    "img_diff = ((img_pt + 1) / 2).clamp(0.0, 1.0) - ((img_tf.to(device) + 1) / 2).clamp(\n",
    "    0.0, 1.0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
